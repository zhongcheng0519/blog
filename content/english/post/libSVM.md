+++
author = "行之"
title = "Embedded Porting of libSVM Inference"
date = "2023-09-19"
description = "Guide to emoji usage in Hugo"
tags = [
    "Machine Learning",
]
+++

In 2020, I mainly worked on algorithms for products designed to prevent falls among the elderly. We secured an IMU sensor on a belt to quickly collect six-axis data from the human body (three-axis acceleration data and three-axis angular velocity data). Then, we fed the collected data into an SVM algorithm using a chip from the STM32F4 series, which eventually yielded a classification result indicating whether there was a risk of falling. Additionally, we trained another classifier on the same data, which was used to determine the user's current posture. In both cases, we used SVM.

SVM (Support Vector Machine) is a rather classic classification algorithm. Before the advent of deep neural networks, SVM performed better than MLP. Its forward inference is also straightforward and can be carried out on low-power MCUs. For training, we used the [libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvm/) library developed by Professor Lin Chih-Jen of National Taiwan University. However, when preparing to port the inference part of libSVM to STM32, we encountered some challenges. 

Compared to the entire libSVM open-source library, its inference part is relatively simple, with the core formula as follows:

$$
\operatorname{sgn}\left(\boldsymbol{w}^{T} \phi(\boldsymbol{x})+b\right)=\operatorname{sgn}\left(\sum_{i=1}^{l} y_{i} \alpha_{i} K\left(\boldsymbol{x}_{i}, \boldsymbol{x}\right)+b\right)
$$

If you want to understand the specific meaning of the formula, you can refer to this [paper](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf).

Such a simple and clear formula, the only thing that needs to be transformed is the kernel function, and the paper also provides the writing of different kernel functions.

On the other hand, after libsvm is trained, it will be saved as a model file. When performing libsvm inference, you need to load this file first. However, in bare-metal development for embedded systems, there is no file system, and even if one could be added, it's quite troublesome. So, I did this: I parsed the model file generated by libsvm myself and generated the corresponding model.h and model.c files. All **data** and **inference methods** are placed in model.h and model.c, so it's very easy to call the svm inference method from outside.

I put this work on my [github](https://github.com/zhongcheng0519/libsvm_for_embeded). It's actually very simple to implement, but it significantly reduces the use of storage in embedded systems and eliminates the need for a file system. If you have the same needs, you can try it out.

<p align="right">(Translated by AI)</p>